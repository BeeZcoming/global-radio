import json
import urllib.request
import urllib.error
import os
import time
from datetime import datetime
import ssl
import math

def fetch_all_stations():
    print("ğŸš€ å¼€å§‹è·å–å…¨çƒç”µå°æ•°æ®...")
    
    # ç¦ç”¨ SSL è¯ä¹¦éªŒè¯
    ssl_context = ssl.create_default_context()
    ssl_context.check_hostname = False
    ssl_context.verify_mode = ssl.CERT_NONE
    
    # ä½¿ç”¨å¤šä¸ª API ç«¯ç‚¹
    base_urls = [
        "https://de1.api.radio-browser.info",
        "https://at1.api.radio-browser.info", 
        "https://nl1.api.radio-browser.info"
    ]
    
    all_stations = []
    max_attempts = 3
    
    for base_url in base_urls:
        print(f"\nğŸ“¡ ä½¿ç”¨ç«¯ç‚¹: {base_url}")
        
        # é¦–å…ˆè·å–æ€»æ•°é‡
        try:
            count_url = f"{base_url}/json/stations?limit=1&hidebroken=true"
            req = urllib.request.Request(count_url, headers={'User-Agent': 'Mozilla/5.0'})
            
            with urllib.request.urlopen(req, context=ssl_context, timeout=30) as response:
                # ä»å“åº”å¤´è·å–æ€»æ•°
                total_count = 0
                if 'x-total-count' in response.headers:
                    total_count = int(response.headers['x-total-count'])
                    print(f"ğŸ“Š è¯¥ç«¯ç‚¹å…±æœ‰ {total_count} ä¸ªç”µå°")
                else:
                    # å¦‚æœæ²¡æœ‰æ€»æ•°å¤´ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    total_count = 10000
                    print(f"âš ï¸ æ— æ³•è·å–æ€»æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼: {total_count}")
            
            # åˆ†é¡µè·å–æ•°æ®
            page_size = 1000  # æ¯é¡µè·å–1000ä¸ª
            pages = math.ceil(total_count / page_size)
            
            print(f"ğŸ“„ éœ€è¦è·å– {pages} é¡µæ•°æ®...")
            
            for page in range(pages):
                offset = page * page_size
                url = f"{base_url}/json/stations?offset={offset}&limit={page_size}&hidebroken=true&order=votes"
                
                for attempt in range(max_attempts):
                    try:
                        print(f"  æ­£åœ¨è·å–ç¬¬ {page + 1}/{pages} é¡µ (offset: {offset})...")
                        
                        req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
                        with urllib.request.urlopen(req, context=ssl_context, timeout=60) as response:
                            data = response.read().decode('utf-8')
                            stations = json.loads(data)
                            
                            if stations:
                                all_stations.extend(stations)
                                print(f"  âœ… è·å–åˆ° {len(stations)} ä¸ªç”µå°")
                                break  # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                            else:
                                print(f"  âš ï¸ ç¬¬ {page + 1} é¡µæ²¡æœ‰æ•°æ®")
                                break
                                
                    except Exception as e:
                        print(f"  âŒ ç¬¬ {page + 1} é¡µè·å–å¤±è´¥ (å°è¯• {attempt + 1}/{max_attempts}): {e}")
                        if attempt < max_attempts - 1:
                            time.sleep(2)  # ç­‰å¾…åé‡è¯•
                        else:
                            print(f"  ğŸ’¥ ç¬¬ {page + 1} é¡µè·å–å¤±è´¥ï¼Œè·³è¿‡")
                
                # é¡µé—´å»¶è¿Ÿ
                time.sleep(1)
                
                # å¦‚æœå·²ç»è·å–è¶³å¤Ÿæ•°æ®ï¼Œæå‰ç»“æŸ
                if len(all_stations) >= 20000:
                    print("ğŸ¯ å·²è·å–è¶³å¤Ÿæ•°æ®ï¼Œæå‰ç»“æŸ")
                    break
                    
        except Exception as e:
            print(f"âŒ ç«¯ç‚¹ {base_url} åˆå§‹åŒ–å¤±è´¥: {e}")
            continue
    
    if not all_stations:
        print("âš ï¸ æ‰€æœ‰ç«¯ç‚¹éƒ½å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®")
        return create_fallback_data()
    
    print(f"\nğŸ“Š æ€»å…±è·å–åˆ° {len(all_stations)} ä¸ªç”µå°")
    return all_stations

def fetch_radio_stations_alternative():
    """å¤‡é€‰æ–¹æ¡ˆï¼šä½¿ç”¨å¤šä¸ªæŸ¥è¯¢æ¡ä»¶è·å–æ•°æ®"""
    print("ğŸ”„ ä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆè·å–æ•°æ®...")
    
    ssl_context = ssl.create_default_context()
    ssl_context.check_hostname = False
    ssl_context.verify_mode = ssl.CERT_NONE
    
    base_urls = [
        "https://de1.api.radio-browser.info",
        "https://at1.api.radio-browser.info"
    ]
    
    all_stations = []
    
    # ä½¿ç”¨ä¸åŒçš„æ’åºå’Œè¿‡æ»¤æ¡ä»¶æ¥è·å–æ›´å¤šæ•°æ®
    queries = [
        "?limit=3000&hidebroken=true&order=votes",  # æŒ‰æŠ•ç¥¨æ•°
        "?limit=3000&hidebroken=true&order=clickcount",  # æŒ‰ç‚¹å‡»é‡
        "?limit=3000&hidebroken=true&order=name",  # æŒ‰åç§°
        "?limit=3000&hidebroken=true&order=country",  # æŒ‰å›½å®¶
        "?limit=3000&hidebroken=true&order=language",  # æŒ‰è¯­è¨€
    ]
    
    for base_url in base_urls:
        print(f"\nğŸ“¡ ä½¿ç”¨ç«¯ç‚¹: {base_url}")
        
        for i, query in enumerate(queries):
            try:
                url = f"{base_url}/json/stations{query}"
                print(f"  æŸ¥è¯¢ {i + 1}/{len(queries)}: {query}")
                
                req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
                with urllib.request.urlopen(req, context=ssl_context, timeout=60) as response:
                    data = response.read().decode('utf-8')
                    stations = json.loads(data)
                    
                    if stations:
                        all_stations.extend(stations)
                        print(f"  âœ… è·å–åˆ° {len(stations)} ä¸ªç”µå°")
                    else:
                        print(f"  âš ï¸ æŸ¥è¯¢æ²¡æœ‰è¿”å›æ•°æ®")
                
                time.sleep(2)  # æŸ¥è¯¢é—´å»¶è¿Ÿ
                
            except Exception as e:
                print(f"  âŒ æŸ¥è¯¢å¤±è´¥: {e}")
                continue
    
    return all_stations

def process_stations_data(raw_stations):
    """å¤„ç†åŸå§‹ç”µå°æ•°æ®"""
    print("ğŸ”„ å¼€å§‹å¤„ç†æ•°æ®...")
    
    # æ•°æ®å»é‡
    unique_stations = []
    seen_uuids = set()
    
    for station in raw_stations:
        uuid = station.get('stationuuid')
        if uuid and uuid not in seen_uuids:
            seen_uuids.add(uuid)
            unique_stations.append(station)
    
    print(f"ğŸ”„ å»é‡åå‰©ä½™ {len(unique_stations)} ä¸ªç”µå°")
    
    # æ•°æ®æ¸…æ´—å’Œä¼˜åŒ–
    processed_stations = []
    valid_count = 0
    invalid_count = 0
    
    for station in unique_stations:
        # è¿‡æ»¤æœ‰æ•ˆç”µå°
        has_url = station.get('url_resolved') or station.get('url')
        has_name = station.get('name') and station.get('name', '').strip()
        is_working = station.get('lastcheckok', True)  # é»˜è®¤ä¸ºTrue
        
        if has_url and has_name and is_working:
            processed_station = {
                'stationuuid': station.get('stationuuid'),
                'name': station.get('name', '').strip(),
                'country': station.get('country', 'Unknown'),
                'countrycode': station.get('countrycode', ''),
                'url_resolved': station.get('url_resolved') or station.get('url'),
                'tags': (station.get('tags') or '').lower()[:100],
                'language': (station.get('language') or '').lower(),
                'votes': station.get('votes', 0),
                'geo_lat': station.get('geo_lat'),
                'geo_long': station.get('geo_long'),
                'lastchecktime': station.get('lastchecktime'),
                'clickcount': station.get('clickcount', 0),
                'bitrate': station.get('bitrate', 0),
                'codec': station.get('codec', '')
            }
            processed_stations.append(processed_station)
            valid_count += 1
        else:
            invalid_count += 1
    
    # æŒ‰æŠ•ç¥¨æ•°æ’åº
    processed_stations.sort(key=lambda x: x.get('votes', 0), reverse=True)
    
    print(f"ğŸ§¹ æ•°æ®æ¸…æ´—å®Œæˆ:")
    print(f"  âœ… æœ‰æ•ˆç”µå°: {valid_count}")
    print(f"  âŒ æ— æ•ˆç”µå°: {invalid_count}")
    print(f"  ğŸ“Š æ€»è®¡: {len(processed_stations)} ä¸ªç”µå°")
    
    return processed_stations

def create_fallback_data():
    """åˆ›å»ºå¤‡ç”¨ç¤ºä¾‹æ•°æ®"""
    print("ğŸ”„ ä½¿ç”¨å¤‡ç”¨ç¤ºä¾‹æ•°æ®")
    # è¿”å›ç©ºæ•°ç»„ï¼Œè®©å‰ç«¯çŸ¥é“æ˜¯å¤‡ç”¨æ•°æ®
    return []

def split_by_region(stations, last_updated):
    """æŒ‰åœ°åŒºåˆ†ç‰‡æ•°æ®"""
    print("ğŸŒ å¼€å§‹æŒ‰åœ°åŒºåˆ†ç‰‡æ•°æ®...")
    
    # å®Œæ•´çš„å›½å®¶åˆ—è¡¨
    region_countries = {
        'asia': [
            'China', 'Japan', 'South Korea', 'India', 'Indonesia', 'Thailand', 
            'Vietnam', 'Malaysia', 'Philippines', 'Singapore', 'Taiwan', 'Hong Kong',
            'Bangladesh', 'Pakistan', 'Sri Lanka', 'Nepal', 'Bhutan', 'Maldives',
            'Myanmar', 'Cambodia', 'Laos', 'Mongolia', 'North Korea', 'Brunei',
            'Timor-Leste', 'Afghanistan', 'Armenia', 'Azerbaijan', 'Bahrain',
            'Georgia', 'Iran', 'Iraq', 'Israel', 'Jordan', 'Kazakhstan', 'Kuwait',
            'Kyrgyzstan', 'Lebanon', 'Oman', 'Qatar', 'Saudi Arabia', 'Syria',
            'Tajikistan', 'Turkey', 'Turkmenistan', 'United Arab Emirates', 'Uzbekistan', 'Yemen'
        ],
        'europe': [
            'United Kingdom', 'Germany', 'France', 'Italy', 'Spain', 'Netherlands',
            'Sweden', 'Norway', 'Finland', 'Denmark', 'Switzerland', 'Austria',
            'Belgium', 'Ireland', 'Portugal', 'Poland', 'Russia', 'Ukraine',
            'Czech Republic', 'Hungary', 'Romania', 'Greece', 'Bulgaria', 'Serbia',
            'Croatia', 'Slovakia', 'Belarus', 'Lithuania', 'Latvia', 'Estonia',
            'Slovenia', 'Luxembourg', 'Malta', 'Cyprus', 'Iceland', 'Albania',
            'Bosnia', 'Macedonia', 'Montenegro', 'Moldova', 'Monaco', 'San Marino',
            'Vatican', 'Liechtenstein', 'Andorra'
        ],
        'americas': [
            'United States', 'Canada', 'Mexico', 'Brazil', 'Argentina', 'Chile',
            'Colombia', 'Peru', 'Venezuela', 'Cuba', 'Ecuador', 'Dominican Republic',
            'Guatemala', 'Bolivia', 'Haiti', 'Paraguay', 'Uruguay', 'Jamaica',
            'Trinidad', 'Bahamas', 'Panama', 'Costa Rica', 'Puerto Rico', 'Honduras',
            'El Salvador', 'Nicaragua', 'Barbados', 'Saint Lucia', 'Grenada',
            'Suriname', 'Guyana', 'Belize', 'Bahamas', 'Saint Vincent', 'Antigua', 'Barbuda'
        ],
        'africa': [
            'South Africa', 'Egypt', 'Nigeria', 'Kenya', 'Morocco', 'Ethiopia',
            'Ghana', 'Tanzania', 'Algeria', 'Uganda', 'Sudan', 'Angola',
            'Mozambique', 'Madagascar', 'Cameroon', 'Ivory Coast', 'Senegal',
            'Zambia', 'Zimbabwe', 'Tunisia', 'Libya', 'Congo', 'Democratic Republic',
            'Somalia', 'Mali', 'Burkina Faso', 'Malawi', 'Niger', 'Chad',
            'Guinea', 'Rwanda', 'Benin', 'Burundi', 'South Sudan', 'Togo',
            'Sierra Leone', 'Central African', 'Liberia', 'Mauritania', 'Eritrea',
            'Namibia', 'Gambia', 'Botswana', 'Gabon', 'Lesotho', 'Guinea-Bissau',
            'Equatorial Guinea', 'Mauritius', 'Eswatini', 'Djibouti', 'Comoros', 'Cabo Verde'
        ],
        'oceania': [
            'Australia', 'New Zealand', 'Fiji', 'Papua New Guinea', 'New Caledonia',
            'Solomon Islands', 'Vanuatu', 'Samoa', 'Tonga', 'Micronesia',
            'Kiribati', 'Marshall Islands', 'Palau', 'Nauru', 'Tuvalu'
        ]
    }
    
    total_regional_stations = 0
    
    for region, countries in region_countries.items():
        region_stations = []
        for station in stations:
            country = station.get('country', '')
            if country and country != 'Unknown':
                # å®½æ¾åŒ¹é…
                country_lower = country.lower()
                for country_name in countries:
                    if country_name.lower() in country_lower or country_lower in country_name.lower():
                        region_stations.append(station)
                        break
        
        output = {
            'lastUpdated': last_updated,
            'totalStations': len(region_stations),
            'region': region,
            'countries': countries,
            'stations': region_stations
        }
        
        with open(f'data/{region}-stations.json', 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… {region}åœ°åŒº: {len(region_stations)} ä¸ªç”µå°")
        total_regional_stations += len(region_stations)
    
    # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡
    print(f"\nğŸ“Š è¯¦ç»†ç»Ÿè®¡:")
    country_stats = {}
    for station in stations:
        country = station.get('country', 'Unknown')
        country_stats[country] = country_stats.get(country, 0) + 1
    
    sorted_countries = sorted(country_stats.items(), key=lambda x: x[1], reverse=True)
    print(f"ğŸŒ æ€»å…± {len(sorted_countries)} ä¸ªå›½å®¶/åœ°åŒº")
    
    # æ˜¾ç¤ºå‰50ä¸ªå›½å®¶
    for i, (country, count) in enumerate(sorted_countries[:50], 1):
        print(f"  {i:2d}. {country}: {count} ä¸ªç”µå°")
    
    if len(sorted_countries) > 50:
        print(f"  ... è¿˜æœ‰ {len(sorted_countries) - 50} ä¸ªå›½å®¶/åœ°åŒº")
    
    print(f"ğŸ“ˆ åœ°åŒºåˆ†ç‰‡å®Œæˆï¼æ€»å…± {total_regional_stations} ä¸ªåœ°åŒºç”µå°")

def main():
    """ä¸»å‡½æ•°"""
    try:
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs('data', exist_ok=True)
        
        current_time = datetime.now().isoformat()
        
        print("=" * 60)
        print("ğŸ¯ å…¨çƒå¹¿æ’­ç”µå°æ•°æ®é‡‡é›†")
        print("=" * 60)
        
        # å°è¯•è·å–å®Œæ•´æ•°æ®
        raw_stations = fetch_all_stations()
        
        # å¦‚æœæ•°æ®å¤ªå°‘ï¼Œå°è¯•å¤‡é€‰æ–¹æ¡ˆ
        if len(raw_stations) < 10000:
            print("\nğŸ”„ æ•°æ®é‡ä¸è¶³ï¼Œå°è¯•å¤‡é€‰æ–¹æ¡ˆ...")
            additional_stations = fetch_radio_stations_alternative()
            raw_stations.extend(additional_stations)
            
            # å†æ¬¡å»é‡
            unique_raw = []
            seen = set()
            for station in raw_stations:
                uuid = station.get('stationuuid')
                if uuid and uuid not in seen:
                    seen.add(uuid)
                    unique_raw.append(station)
            raw_stations = unique_raw
        
        print(f"\nğŸ“Š åŸå§‹æ•°æ®: {len(raw_stations)} ä¸ªç”µå°")
        
        # å¤„ç†æ•°æ®
        processed_stations = process_stations_data(raw_stations)
        
        if not processed_stations:
            print("ğŸ’¥ æ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œåˆ›å»ºç©ºæ•°æ®é›†")
            processed_stations = []
        
        # ä¿å­˜ç²¾é€‰æ•°æ®
        curated_output = {
            'lastUpdated': current_time,
            'totalStations': len(processed_stations),
            'source': 'Radio Browser API',
            'note': 'æ•°æ®é€šè¿‡åˆ†é¡µå’Œå¤šç«¯ç‚¹é‡‡é›†',
            'stations': processed_stations
        }
        
        with open('data/curated-stations.json', 'w', encoding='utf-8') as f:
            json.dump(curated_output, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ç²¾é€‰æ•°æ®ä¿å­˜å®Œæˆï¼")
        print(f"  æ–‡ä»¶: data/curated-stations.json")
        print(f"  ç”µå°æ•°: {len(processed_stations)}")
        
        # æŒ‰åœ°åŒºåˆ†ç‰‡
        if processed_stations:
            split_by_region(processed_stations, current_time)
        else:
            print("âš ï¸ æ²¡æœ‰æ•°æ®å¯åˆ†åŒº")
        
        print("\nğŸ‰ æ•°æ®é¢„å¤„ç†å®Œæˆï¼")
        
    except Exception as e:
        print(f"ğŸ’¥ é¢„å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
