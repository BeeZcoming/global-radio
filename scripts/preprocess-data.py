import json
import urllib.request
import urllib.error
import os
import time
from datetime import datetime
import ssl
import math

def test_api_endpoint(base_url):
    """æµ‹è¯• API ç«¯ç‚¹æ˜¯å¦å¯ç”¨"""
    ssl_context = ssl.create_default_context()
    ssl_context.check_hostname = False
    ssl_context.verify_mode = ssl.CERT_NONE
    
    try:
        test_url = f"{base_url}/json/stations?limit=1"
        req = urllib.request.Request(test_url, headers={'User-Agent': 'Mozilla/5.0'})
        
        with urllib.request.urlopen(req, context=ssl_context, timeout=10) as response:
            data = response.read().decode('utf-8')
            stations = json.loads(data)
            return len(stations) > 0
    except Exception as e:
        print(f"  âŒ ç«¯ç‚¹æµ‹è¯•å¤±è´¥: {e}")
        return False

def get_total_count(base_url, ssl_context):
    """è·å–ç”µå°æ€»æ•°"""
    try:
        count_url = f"{base_url}/json/stations?limit=1&hidebroken=true"
        req = urllib.request.Request(count_url, headers={'User-Agent': 'Mozilla/5.0'})
        
        with urllib.request.urlopen(req, context=ssl_context, timeout=30) as response:
            if 'x-total-count' in response.headers:
                total_count = int(response.headers['x-total-count'])
                print(f"ğŸ“Š API æŠ¥å‘Šæ€»æ•°: {total_count} ä¸ªç”µå°")
                return total_count
            else:
                # å¦‚æœæ²¡æœ‰æ€»æ•°å¤´ä¿¡æ¯ï¼Œå°è¯•ç›´æ¥è·å–å¤§é‡æ•°æ®æ¥ä¼°ç®—
                test_url = f"{base_url}/json/stations?limit=5000&hidebroken=true"
                req = urllib.request.Request(test_url, headers={'User-Agent': 'Mozilla/5.0'})
                with urllib.request.urlopen(req, context=ssl_context, timeout=30) as resp:
                    data = resp.read().decode('utf-8')
                    stations = json.loads(data)
                    estimated_count = len(stations) * 6  # ç²—ç•¥ä¼°ç®—
                    print(f"ğŸ“Š ä¼°ç®—æ€»æ•°: {estimated_count} ä¸ªç”µå°")
                    return min(estimated_count, 35000)  # é™åˆ¶æœ€å¤§æ•°é‡
    except Exception as e:
        print(f"âŒ è·å–æ€»æ•°å¤±è´¥: {e}")
        return 30000  # é»˜è®¤å€¼

def fetch_all_stations():
    print("ğŸš€ å¼€å§‹è·å–å…¨çƒç”µå°æ•°æ®...")
    
    # ç¦ç”¨ SSL è¯ä¹¦éªŒè¯
    ssl_context = ssl.create_default_context()
    ssl_context.check_hostname = False
    ssl_context.verify_mode = ssl.CERT_NONE
    
    # æµ‹è¯•å¯ç”¨çš„ç«¯ç‚¹
    potential_urls = [
        "https://de1.api.radio-browser.info",
        "https://at1.api.radio-browser.info", 
        "https://nl1.api.radio-browser.info"
    ]
    
    available_urls = []
    print("ğŸ” æµ‹è¯• API ç«¯ç‚¹å¯ç”¨æ€§...")
    for url in potential_urls:
        print(f"  æµ‹è¯• {url}...")
        if test_api_endpoint(url):
            available_urls.append(url)
            print(f"  âœ… å¯ç”¨")
        else:
            print(f"  âŒ ä¸å¯ç”¨")
    
    if not available_urls:
        print("ğŸ’¥ æ‰€æœ‰ç«¯ç‚¹éƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨ de1 ä½œä¸ºå¤‡ç”¨")
        available_urls = ["https://de1.api.radio-browser.info"]
    
    print(f"ğŸ¯ å¯ç”¨ç«¯ç‚¹: {available_urls}")
    
    all_stations = []
    max_attempts = 3
    
    for base_url in available_urls:
        print(f"\nğŸ“¡ ä½¿ç”¨ç«¯ç‚¹: {base_url}")
        
        try:
            # è·å–æ€»æ•°é‡
            total_count = get_total_count(base_url, ssl_context)
            
            # åˆ†é¡µè·å–æ•°æ®
            page_size = 1000  # æ¯é¡µè·å–1000ä¸ªï¼Œé¿å…è¿‡å¤§è¯·æ±‚
            pages = math.ceil(total_count / page_size)
            
            # é™åˆ¶æœ€å¤§é¡µæ•°ï¼Œä½†ç¡®ä¿èƒ½è·å–è¶³å¤Ÿæ•°æ®
            max_pages = 35  # 35000ä¸ªç”µå°
            pages = min(pages, max_pages)
            
            print(f"ğŸ“„ è®¡åˆ’è·å– {pages} é¡µæ•°æ®ï¼Œç›®æ ‡: {total_count} ä¸ªç”µå°...")
            
            successful_pages = 0
            for page in range(pages):
                offset = page * page_size
                url = f"{base_url}/json/stations?offset={offset}&limit={page_size}&hidebroken=true"
                
                for attempt in range(max_attempts):
                    try:
                        print(f"  æ­£åœ¨è·å–ç¬¬ {page + 1}/{pages} é¡µ (offset: {offset})...")
                        
                        req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
                        with urllib.request.urlopen(req, context=ssl_context, timeout=60) as response:
                            data = response.read().decode('utf-8')
                            stations = json.loads(data)
                            
                            if stations:
                                all_stations.extend(stations)
                                successful_pages += 1
                                print(f"  âœ… è·å–åˆ° {len(stations)} ä¸ªç”µå°")
                                print(f"  ğŸ“ˆ ç´¯è®¡: {len(all_stations)} ä¸ªç”µå°")
                                break
                            else:
                                print(f"  âš ï¸ ç¬¬ {page + 1} é¡µæ²¡æœ‰æ•°æ®ï¼Œå¯èƒ½å·²åˆ°æœ«å°¾")
                                break
                                
                    except Exception as e:
                        print(f"  âŒ ç¬¬ {page + 1} é¡µè·å–å¤±è´¥ (å°è¯• {attempt + 1}/{max_attempts}): {e}")
                        if attempt < max_attempts - 1:
                            time.sleep(2)
                        else:
                            print(f"  ğŸ’¥ ç¬¬ {page + 1} é¡µè·å–å¤±è´¥ï¼Œè·³è¿‡")
                            break
                
                # é¡µé—´å»¶è¿Ÿ
                time.sleep(1)
                
                # å¦‚æœè¿ç»­3é¡µæ²¡æœ‰æ•°æ®ï¼Œæå‰ç»“æŸ
                if page > 2 and len(all_stations) == 0:
                    print("ğŸ’¥ è¿ç»­å¤šé¡µæ²¡æœ‰æ•°æ®ï¼Œæå‰ç»“æŸ")
                    break
                    
            print(f"ğŸ“Š ä» {base_url} æˆåŠŸè·å– {successful_pages}/{pages} é¡µæ•°æ®")
                    
        except Exception as e:
            print(f"âŒ ç«¯ç‚¹ {base_url} å¤„ç†å¤±è´¥: {e}")
            continue
        
        # å¦‚æœä»ä¸€ä¸ªç«¯ç‚¹è·å–äº†è¶³å¤Ÿæ•°æ®ï¼Œå¯ä»¥æå‰ç»“æŸ
        if len(all_stations) >= 28000:
            print("ğŸ¯ å·²è·å–æ¥è¿‘å®Œæ•´æ•°æ®ï¼Œæå‰ç»“æŸ")
            break
    
    return all_stations

def fetch_additional_stations():
    """ä½¿ç”¨ä¸åŒæ’åºæ–¹å¼è·å–æ›´å¤šæ•°æ®"""
    print("\nğŸ”„ ä½¿ç”¨ä¸åŒæ’åºæ–¹å¼è·å–è¡¥å……æ•°æ®...")
    
    ssl_context = ssl.create_default_context()
    ssl_context.check_hostname = False
    ssl_context.verify_mode = ssl.CERT_NONE
    
    base_url = "https://de1.api.radio-browser.info"
    additional_stations = []
    
    # ä½¿ç”¨ä¸åŒçš„æ’åºæ–¹å¼
    sort_methods = [
        "order=votes",
        "order=clickcount", 
        "order=name",
        "order=country",
        "order=state",
        "order=language",
        "order=tags"
    ]
    
    for i, sort_method in enumerate(sort_methods):
        try:
            url = f"{base_url}/json/stations?limit=5000&hidebroken=true&{sort_method}"
            print(f"  è¡¥å……æŸ¥è¯¢ {i + 1}/{len(sort_methods)}: {sort_method}")
            
            req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
            with urllib.request.urlopen(req, context=ssl_context, timeout=60) as response:
                data = response.read().decode('utf-8')
                stations = json.loads(data)
                
                if stations:
                    additional_stations.extend(stations)
                    print(f"  âœ… è·å–åˆ° {len(stations)} ä¸ªç”µå°")
                else:
                    print(f"  âš ï¸ æŸ¥è¯¢æ²¡æœ‰è¿”å›æ•°æ®")
            
            time.sleep(1)
            
        except Exception as e:
            print(f"  âŒ è¡¥å……æŸ¥è¯¢å¤±è´¥: {e}")
            continue
    
    return additional_stations

def process_stations_data(raw_stations):
    """å¤„ç†åŸå§‹ç”µå°æ•°æ®"""
    print("ğŸ”„ å¼€å§‹å¤„ç†æ•°æ®...")
    
    if not raw_stations:
        print("ğŸ’¥ æ²¡æœ‰åŸå§‹æ•°æ®å¯å¤„ç†")
        return []
    
    print(f"ğŸ“Š åŸå§‹æ•°æ®: {len(raw_stations)} ä¸ªç”µå°")
    
    # æ•°æ®å»é‡
    unique_stations = []
    seen_uuids = set()
    
    for station in raw_stations:
        uuid = station.get('stationuuid')
        if uuid and uuid not in seen_uuids:
            seen_uuids.add(uuid)
            unique_stations.append(station)
    
    print(f"ğŸ”„ å»é‡åå‰©ä½™ {len(unique_stations)} ä¸ªç”µå°")
    
    # æ•°æ®æ¸…æ´—å’Œä¼˜åŒ–
    processed_stations = []
    valid_count = 0
    invalid_count = 0
    
    for station in unique_stations:
        # æ”¾å®½è¿‡æ»¤æ¡ä»¶ï¼Œè·å–æ›´å¤šç”µå°
        has_url = station.get('url_resolved') or station.get('url')
        has_name = station.get('name') and station.get('name', '').strip()
        
        if has_url and has_name:
            processed_station = {
                'stationuuid': station.get('stationuuid'),
                'name': station.get('name', '').strip(),
                'country': station.get('country', 'Unknown'),
                'countrycode': station.get('countrycode', ''),
                'url_resolved': station.get('url_resolved') or station.get('url'),
                'tags': (station.get('tags') or '').lower()[:100],
                'language': (station.get('language') or '').lower(),
                'votes': station.get('votes', 0),
                'geo_lat': station.get('geo_lat'),
                'geo_long': station.get('geo_long'),
                'lastchecktime': station.get('lastchecktime'),
                'clickcount': station.get('clickcount', 0),
                'bitrate': station.get('bitrate', 0),
                'codec': station.get('codec', '')
            }
            processed_stations.append(processed_station)
            valid_count += 1
        else:
            invalid_count += 1
    
    # æŒ‰æŠ•ç¥¨æ•°æ’åº
    processed_stations.sort(key=lambda x: x.get('votes', 0), reverse=True)
    
    print(f"ğŸ§¹ æ•°æ®æ¸…æ´—å®Œæˆ:")
    print(f"  âœ… æœ‰æ•ˆç”µå°: {valid_count}")
    print(f"  âŒ æ— æ•ˆç”µå°: {invalid_count}")
    print(f"  ğŸ“Š æ€»è®¡: {len(processed_stations)} ä¸ªç”µå°")
    
    return processed_stations

def split_by_region(stations, last_updated):
    """æŒ‰åœ°åŒºåˆ†ç‰‡æ•°æ®"""
    print("ğŸŒ å¼€å§‹æŒ‰åœ°åŒºåˆ†ç‰‡æ•°æ®...")
    
    if not stations:
        print("âš ï¸ æ²¡æœ‰æ•°æ®å¯åˆ†åŒº")
        return
    
    # å®Œæ•´çš„å›½å®¶åˆ—è¡¨
    region_countries = {
        'asia': [
            'China', 'Japan', 'South Korea', 'India', 'Indonesia', 'Thailand', 
            'Vietnam', 'Malaysia', 'Philippines', 'Singapore', 'Taiwan', 'Hong Kong',
            'Bangladesh', 'Pakistan', 'Sri Lanka', 'Nepal', 'Bhutan', 'Maldives',
            'Myanmar', 'Cambodia', 'Laos', 'Mongolia', 'North Korea', 'Brunei',
            'Timor-Leste', 'Afghanistan', 'Armenia', 'Azerbaijan', 'Bahrain',
            'Georgia', 'Iran', 'Iraq', 'Israel', 'Jordan', 'Kazakhstan', 'Kuwait',
            'Kyrgyzstan', 'Lebanon', 'Oman', 'Qatar', 'Saudi Arabia', 'Syria',
            'Tajikistan', 'Turkey', 'Turkmenistan', 'United Arab Emirates', 'Uzbekistan', 'Yemen'
        ],
        'europe': [
            'United Kingdom', 'Germany', 'France', 'Italy', 'Spain', 'Netherlands',
            'Sweden', 'Norway', 'Finland', 'Denmark', 'Switzerland', 'Austria',
            'Belgium', 'Ireland', 'Portugal', 'Poland', 'Russia', 'Ukraine',
            'Czech Republic', 'Hungary', 'Romania', 'Greece', 'Bulgaria', 'Serbia',
            'Croatia', 'Slovakia', 'Belarus', 'Lithuania', 'Latvia', 'Estonia',
            'Slovenia', 'Luxembourg', 'Malta', 'Cyprus', 'Iceland', 'Albania',
            'Bosnia', 'Macedonia', 'Montenegro', 'Moldova', 'Monaco', 'San Marino',
            'Vatican', 'Liechtenstein', 'Andorra'
        ],
        'americas': [
            'United States', 'Canada', 'Mexico', 'Brazil', 'Argentina', 'Chile',
            'Colombia', 'Peru', 'Venezuela', 'Cuba', 'Ecuador', 'Dominican Republic',
            'Guatemala', 'Bolivia', 'Haiti', 'Paraguay', 'Uruguay', 'Jamaica',
            'Trinidad', 'Bahamas', 'Panama', 'Costa Rica', 'Puerto Rico', 'Honduras',
            'El Salvador', 'Nicaragua', 'Barbados', 'Saint Lucia', 'Grenada',
            'Suriname', 'Guyana', 'Belize', 'Bahamas', 'Saint Vincent', 'Antigua', 'Barbuda'
        ],
        'africa': [
            'South Africa', 'Egypt', 'Nigeria', 'Kenya', 'Morocco', 'Ethiopia',
            'Ghana', 'Tanzania', 'Algeria', 'Uganda', 'Sudan', 'Angola',
            'Mozambique', 'Madagascar', 'Cameroon', 'Ivory Coast', 'Senegal',
            'Zambia', 'Zimbabwe', 'Tunisia', 'Libya', 'Congo', 'Democratic Republic',
            'Somalia', 'Mali', 'Burkina Faso', 'Malawi', 'Niger', 'Chad',
            'Guinea', 'Rwanda', 'Benin', 'Burundi', 'South Sudan', 'Togo',
            'Sierra Leone', 'Central African', 'Liberia', 'Mauritania', 'Eritrea',
            'Namibia', 'Gambia', 'Botswana', 'Gabon', 'Lesotho', 'Guinea-Bissau',
            'Equatorial Guinea', 'Mauritius', 'Eswatini', 'Djibouti', 'Comoros', 'Cabo Verde'
        ],
        'oceania': [
            'Australia', 'New Zealand', 'Fiji', 'Papua New Guinea', 'New Caledonia',
            'Solomon Islands', 'Vanuatu', 'Samoa', 'Tonga', 'Micronesia',
            'Kiribati', 'Marshall Islands', 'Palau', 'Nauru', 'Tuvalu'
        ]
    }
    
    total_regional_stations = 0
    
    for region, countries in region_countries.items():
        region_stations = []
        for station in stations:
            country = station.get('country', '')
            if country and country != 'Unknown':
                # å®½æ¾åŒ¹é…
                country_lower = country.lower()
                for country_name in countries:
                    if country_name.lower() in country_lower or country_lower in country_name.lower():
                        region_stations.append(station)
                        break
        
        output = {
            'lastUpdated': last_updated,
            'totalStations': len(region_stations),
            'region': region,
            'countries': countries,
            'stations': region_stations
        }
        
        with open(f'data/{region}-stations.json', 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… {region}åœ°åŒº: {len(region_stations)} ä¸ªç”µå°")
        total_regional_stations += len(region_stations)
    
    # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡
    print(f"\nğŸ“Š è¯¦ç»†ç»Ÿè®¡:")
    country_stats = {}
    for station in stations:
        country = station.get('country', 'Unknown')
        country_stats[country] = country_stats.get(country, 0) + 1
    
    sorted_countries = sorted(country_stats.items(), key=lambda x: x[1], reverse=True)
    print(f"ğŸŒ æ€»å…± {len(sorted_countries)} ä¸ªå›½å®¶/åœ°åŒº")
    
    # æ˜¾ç¤ºå‰30ä¸ªå›½å®¶
    for i, (country, count) in enumerate(sorted_countries[:30], 1):
        print(f"  {i:2d}. {country}: {count} ä¸ªç”µå°")
    
    if len(sorted_countries) > 30:
        print(f"  ... è¿˜æœ‰ {len(sorted_countries) - 30} ä¸ªå›½å®¶/åœ°åŒº")
    
    print(f"ğŸ“ˆ åœ°åŒºåˆ†ç‰‡å®Œæˆï¼æ€»å…± {total_regional_stations} ä¸ªåœ°åŒºç”µå°")

def main():
    """ä¸»å‡½æ•°"""
    try:
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs('data', exist_ok=True)
        
        current_time = datetime.now().isoformat()
        
        print("=" * 60)
        print("ğŸ¯ å…¨çƒå¹¿æ’­ç”µå°æ•°æ®é‡‡é›† - å®Œæ•´ç‰ˆæœ¬")
        print("=" * 60)
        
        # ç¬¬ä¸€é˜¶æ®µï¼šåˆ†é¡µè·å–ä¸»è¦æ•°æ®
        raw_stations = fetch_all_stations()
        
        # ç¬¬äºŒé˜¶æ®µï¼šä½¿ç”¨ä¸åŒæ’åºæ–¹å¼è·å–è¡¥å……æ•°æ®
        if len(raw_stations) < 25000:
            print(f"\nğŸ”„ ç¬¬ä¸€é˜¶æ®µåªè·å–äº† {len(raw_stations)} ä¸ªç”µå°ï¼Œå¼€å§‹ç¬¬äºŒé˜¶æ®µ...")
            additional_stations = fetch_additional_stations()
            raw_stations.extend(additional_stations)
            
            # å»é‡
            unique_raw = []
            seen = set()
            for station in raw_stations:
                uuid = station.get('stationuuid')
                if uuid and uuid not in seen:
                    seen.add(uuid)
                    unique_raw.append(station)
            raw_stations = unique_raw
            print(f"ğŸ“Š åˆå¹¶ååŸå§‹æ•°æ®: {len(raw_stations)} ä¸ªç”µå°")
        
        # å¤„ç†æ•°æ®
        processed_stations = process_stations_data(raw_stations)
        
        if not processed_stations:
            print("ğŸ’¥ æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
            processed_stations = []
        
        # ä¿å­˜ç²¾é€‰æ•°æ®
        curated_output = {
            'lastUpdated': current_time,
            'totalStations': len(processed_stations),
            'source': 'Radio Browser API',
            'note': f'é€šè¿‡åˆ†é¡µå’Œå¤šç§æ’åºæ–¹å¼é‡‡é›†ï¼ŒåŸå§‹æ•°æ®: {len(raw_stations)} ä¸ªç”µå°',
            'stations': processed_stations
        }
        
        with open('data/curated-stations.json', 'w', encoding='utf-8') as f:
            json.dump(curated_output, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ç²¾é€‰æ•°æ®ä¿å­˜å®Œæˆï¼")
        print(f"  æ–‡ä»¶: data/curated-stations.json")
        print(f"  æœ‰æ•ˆç”µå°æ•°: {len(processed_stations)}")
        print(f"  åŸå§‹ç”µå°æ•°: {len(raw_stations)}")
        
        # æŒ‰åœ°åŒºåˆ†ç‰‡
        if processed_stations:
            split_by_region(processed_stations, current_time)
        else:
            print("âš ï¸ æ²¡æœ‰æ•°æ®å¯åˆ†åŒº")
        
        print("\nğŸ‰ æ•°æ®é¢„å¤„ç†å®Œæˆï¼")
        
    except Exception as e:
        print(f"ğŸ’¥ é¢„å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
